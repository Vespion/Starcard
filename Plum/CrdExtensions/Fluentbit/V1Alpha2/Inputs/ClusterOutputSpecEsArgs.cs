// *** WARNING: this file was generated by crd2pulumi. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Kubernetes.Types.Inputs.Fluentbit.V1Alpha2
{

    /// <summary>
    /// Elasticsearch defines Elasticsearch Output configuration.
    /// </summary>
    public class ClusterOutputSpecEsArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Enable AWS Sigv4 Authentication for Amazon ElasticSearch Service.
        /// </summary>
        [Input("awsAuth")]
        public Input<string>? AwsAuth { get; set; }

        /// <summary>
        /// External ID for the AWS IAM Role specified with aws_role_arn.
        /// </summary>
        [Input("awsExternalID")]
        public Input<string>? AwsExternalID { get; set; }

        /// <summary>
        /// Specify the AWS region for Amazon ElasticSearch Service.
        /// </summary>
        [Input("awsRegion")]
        public Input<string>? AwsRegion { get; set; }

        /// <summary>
        /// AWS IAM Role to assume to put records to your Amazon ES cluster.
        /// </summary>
        [Input("awsRoleARN")]
        public Input<string>? AwsRoleARN { get; set; }

        /// <summary>
        /// Specify the custom sts endpoint to be used with STS API for Amazon ElasticSearch Service.
        /// </summary>
        [Input("awsSTSEndpoint")]
        public Input<string>? AwsSTSEndpoint { get; set; }

        /// <summary>
        /// Specify the buffer size used to read the response from the Elasticsearch HTTP service. This option is useful for debugging purposes where is required to read full responses, note that response size grows depending of the number of records inserted. To set an unlimited amount of memory set this value to False, otherwise the value must be according to the Unit Size specification.
        /// </summary>
        [Input("bufferSize")]
        public Input<string>? BufferSize { get; set; }

        /// <summary>
        /// Specify the credentials to use to connect to Elastic's Elasticsearch Service running on Elastic Cloud.
        /// </summary>
        [Input("cloudAuth")]
        public Input<string>? CloudAuth { get; set; }

        /// <summary>
        /// If you are using Elastic's Elasticsearch Service you can specify the cloud_id of the cluster running.
        /// </summary>
        [Input("cloudID")]
        public Input<string>? CloudID { get; set; }

        /// <summary>
        /// Use current time for index generation instead of message record
        /// </summary>
        [Input("currentTimeIndex")]
        public Input<bool>? CurrentTimeIndex { get; set; }

        /// <summary>
        /// When enabled, generate _id for outgoing records. This prevents duplicate records when retrying ES.
        /// </summary>
        [Input("generateID")]
        public Input<bool>? GenerateID { get; set; }

        /// <summary>
        /// IP address or hostname of the target Elasticsearch instance
        /// </summary>
        [Input("host")]
        public Input<string>? Host { get; set; }

        /// <summary>
        /// Password for user defined in HTTP_User
        /// </summary>
        [Input("httpPassword")]
        public Input<Pulumi.Kubernetes.Types.Inputs.Fluentbit.V1Alpha2.ClusterOutputSpecEsHttppasswordArgs>? HttpPassword { get; set; }

        /// <summary>
        /// Optional username credential for Elastic X-Pack access
        /// </summary>
        [Input("httpUser")]
        public Input<Pulumi.Kubernetes.Types.Inputs.Fluentbit.V1Alpha2.ClusterOutputSpecEsHttpuserArgs>? HttpUser { get; set; }

        /// <summary>
        /// If set, _id will be the value of the key from incoming record and Generate_ID option is ignored.
        /// </summary>
        [Input("idKey")]
        public Input<string>? IdKey { get; set; }

        /// <summary>
        /// When enabled, it append the Tag name to the record.
        /// </summary>
        [Input("includeTagKey")]
        public Input<bool>? IncludeTagKey { get; set; }

        /// <summary>
        /// Index name
        /// </summary>
        [Input("index")]
        public Input<string>? Index { get; set; }

        /// <summary>
        /// Time format (based on strftime) to generate the second part of the Index name.
        /// </summary>
        [Input("logstashDateFormat")]
        public Input<string>? LogstashDateFormat { get; set; }

        /// <summary>
        /// Enable Logstash format compatibility. This option takes a boolean value: True/False, On/Off
        /// </summary>
        [Input("logstashFormat")]
        public Input<bool>? LogstashFormat { get; set; }

        /// <summary>
        /// When Logstash_Format is enabled, the Index name is composed using a prefix and the date, e.g: If Logstash_Prefix is equals to 'mydata' your index will become 'mydata-YYYY.MM.DD'. The last string appended belongs to the date when the data is being generated.
        /// </summary>
        [Input("logstashPrefix")]
        public Input<string>? LogstashPrefix { get; set; }

        /// <summary>
        /// Prefix keys with this string
        /// </summary>
        [Input("logstashPrefixKey")]
        public Input<string>? LogstashPrefixKey { get; set; }

        /// <summary>
        /// Elasticsearch accepts new data on HTTP query path "/_bulk". But it is also possible to serve Elasticsearch behind a reverse proxy on a subpath. This option defines such path on the fluent-bit side. It simply adds a path prefix in the indexing HTTP POST URI.
        /// </summary>
        [Input("path")]
        public Input<string>? Path { get; set; }

        /// <summary>
        /// Newer versions of Elasticsearch allows setting up filters called pipelines. This option allows defining which pipeline the database should use. For performance reasons is strongly suggested parsing and filtering on Fluent Bit side, avoid pipelines.
        /// </summary>
        [Input("pipeline")]
        public Input<string>? Pipeline { get; set; }

        /// <summary>
        /// TCP port of the target Elasticsearch instance
        /// </summary>
        [Input("port")]
        public Input<int>? Port { get; set; }

        /// <summary>
        /// When enabled, replace field name dots with underscore, required by Elasticsearch 2.0-2.3.
        /// </summary>
        [Input("replaceDots")]
        public Input<bool>? ReplaceDots { get; set; }

        /// <summary>
        /// When enabled, mapping types is removed and Type option is ignored. Types are deprecated in APIs in v7.0. This options is for v7.0 or later.
        /// </summary>
        [Input("suppressTypeName")]
        public Input<string>? SuppressTypeName { get; set; }

        /// <summary>
        /// When Include_Tag_Key is enabled, this property defines the key name for the tag.
        /// </summary>
        [Input("tagKey")]
        public Input<string>? TagKey { get; set; }

        /// <summary>
        /// When Logstash_Format is enabled, each record will get a new timestamp field. The Time_Key property defines the name of that field.
        /// </summary>
        [Input("timeKey")]
        public Input<string>? TimeKey { get; set; }

        /// <summary>
        /// When Logstash_Format is enabled, this property defines the format of the timestamp.
        /// </summary>
        [Input("timeKeyFormat")]
        public Input<string>? TimeKeyFormat { get; set; }

        /// <summary>
        /// When Logstash_Format is enabled, enabling this property sends nanosecond precision timestamps.
        /// </summary>
        [Input("timeKeyNanos")]
        public Input<bool>? TimeKeyNanos { get; set; }

        /// <summary>
        /// Fluent Bit provides integrated support for Transport Layer Security (TLS) and it predecessor Secure Sockets Layer (SSL) respectively.
        /// </summary>
        [Input("tls")]
        public Input<Pulumi.Kubernetes.Types.Inputs.Fluentbit.V1Alpha2.ClusterOutputSpecEsTlsArgs>? Tls { get; set; }

        /// <summary>
        /// When enabled print the elasticsearch API calls to stdout when elasticsearch returns an error
        /// </summary>
        [Input("traceError")]
        public Input<bool>? TraceError { get; set; }

        /// <summary>
        /// When enabled print the elasticsearch API calls to stdout (for diag only)
        /// </summary>
        [Input("traceOutput")]
        public Input<bool>? TraceOutput { get; set; }

        /// <summary>
        /// Type name
        /// </summary>
        [Input("type")]
        public Input<string>? Type { get; set; }

        public ClusterOutputSpecEsArgs()
        {
        }
        public static new ClusterOutputSpecEsArgs Empty => new ClusterOutputSpecEsArgs();
    }
}
