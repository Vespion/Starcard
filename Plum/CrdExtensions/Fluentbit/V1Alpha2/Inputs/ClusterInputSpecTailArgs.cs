// *** WARNING: this file was generated by crd2pulumi. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Kubernetes.Types.Inputs.Fluentbit.V1Alpha2
{

    /// <summary>
    /// Tail defines Tail Input configuration.
    /// </summary>
    public class ClusterInputSpecTailArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Set the initial buffer size to read files data. This value is used too to increase buffer size. The value must be according to the Unit Size specification.
        /// </summary>
        [Input("bufferChunkSize")]
        public Input<string>? BufferChunkSize { get; set; }

        /// <summary>
        /// Set the limit of the buffer size per monitored file. When a buffer needs to be increased (e.g: very long lines), this value is used to restrict how much the memory buffer can grow. If reading a file exceed this limit, the file is removed from the monitored file list The value must be according to the Unit Size specification.
        /// </summary>
        [Input("bufferMaxSize")]
        public Input<string>? BufferMaxSize { get; set; }

        /// <summary>
        /// Specify the database file to keep track of monitored files and offsets.
        /// </summary>
        [Input("db")]
        public Input<string>? Db { get; set; }

        /// <summary>
        /// Set a default synchronization (I/O) method. Values: Extra, Full, Normal, Off.
        /// </summary>
        [Input("dbSync")]
        public Input<string>? DbSync { get; set; }

        /// <summary>
        /// DisableInotifyWatcher will disable inotify and use the file stat watcher instead.
        /// </summary>
        [Input("disableInotifyWatcher")]
        public Input<bool>? DisableInotifyWatcher { get; set; }

        /// <summary>
        /// If enabled, the plugin will recombine split Docker log lines before passing them to any parser as configured above. This mode cannot be used at the same time as Multiline.
        /// </summary>
        [Input("dockerMode")]
        public Input<bool>? DockerMode { get; set; }

        /// <summary>
        /// Wait period time in seconds to flush queued unfinished split lines.
        /// </summary>
        [Input("dockerModeFlushSeconds")]
        public Input<int>? DockerModeFlushSeconds { get; set; }

        /// <summary>
        /// Specify an optional parser for the first line of the docker multiline mode. The parser name to be specified must be registered in the parsers.conf file.
        /// </summary>
        [Input("dockerModeParser")]
        public Input<string>? DockerModeParser { get; set; }

        /// <summary>
        /// Set one or multiple shell patterns separated by commas to exclude files matching a certain criteria, e.g: exclude_path=*.gz,*.zip
        /// </summary>
        [Input("excludePath")]
        public Input<string>? ExcludePath { get; set; }

        /// <summary>
        /// Ignores records which are older than this time in seconds. Supports m,h,d (minutes, hours, days) syntax. Default behavior is to read all records from specified files. Only available when a Parser is specificied and it can parse the time of a record.
        /// </summary>
        [Input("ignoredOlder")]
        public Input<string>? IgnoredOlder { get; set; }

        /// <summary>
        /// When a message is unstructured (no parser applied), it's appended as a string under the key name log. This option allows to define an alternative name for that key.
        /// </summary>
        [Input("key")]
        public Input<string>? Key { get; set; }

        /// <summary>
        /// Set a limit of memory that Tail plugin can use when appending data to the Engine. If the limit is reach, it will be paused; when the data is flushed it resumes.
        /// </summary>
        [Input("memBufLimit")]
        public Input<string>? MemBufLimit { get; set; }

        /// <summary>
        /// If enabled, the plugin will try to discover multiline messages and use the proper parsers to compose the outgoing messages. Note that when this option is enabled the Parser option is not used.
        /// </summary>
        [Input("multiline")]
        public Input<bool>? Multiline { get; set; }

        /// <summary>
        /// Wait period time in seconds to process queued multiline messages
        /// </summary>
        [Input("multilineFlushSeconds")]
        public Input<int>? MultilineFlushSeconds { get; set; }

        /// <summary>
        /// This will help to reassembly multiline messages originally split by Docker or CRI Specify one or Multiline Parser definition to apply to the content.
        /// </summary>
        [Input("multilineParser")]
        public Input<string>? MultilineParser { get; set; }

        /// <summary>
        /// Specify the name of a parser to interpret the entry as a structured message.
        /// </summary>
        [Input("parser")]
        public Input<string>? Parser { get; set; }

        /// <summary>
        /// Name of the parser that matchs the beginning of a multiline message. Note that the regular expression defined in the parser must include a group name (named capture)
        /// </summary>
        [Input("parserFirstline")]
        public Input<string>? ParserFirstline { get; set; }

        [Input("parserN")]
        private InputList<string>? _parserN;

        /// <summary>
        /// Optional-extra parser to interpret and structure multiline entries. This option can be used to define multiple parsers.
        /// </summary>
        public InputList<string> ParserN
        {
            get => _parserN ?? (_parserN = new InputList<string>());
            set => _parserN = value;
        }

        /// <summary>
        /// Pattern specifying a specific log files or multiple ones through the use of common wildcards.
        /// </summary>
        [Input("path")]
        public Input<string>? Path { get; set; }

        /// <summary>
        /// If enabled, it appends the name of the monitored file as part of the record. The value assigned becomes the key in the map.
        /// </summary>
        [Input("pathKey")]
        public Input<string>? PathKey { get; set; }

        /// <summary>
        /// For new discovered files on start (without a database offset/position), read the content from the head of the file, not tail.
        /// </summary>
        [Input("readFromHead")]
        public Input<bool>? ReadFromHead { get; set; }

        /// <summary>
        /// The interval of refreshing the list of watched files in seconds.
        /// </summary>
        [Input("refreshIntervalSeconds")]
        public Input<int>? RefreshIntervalSeconds { get; set; }

        /// <summary>
        /// Specify the number of extra time in seconds to monitor a file once is rotated in case some pending data is flushed.
        /// </summary>
        [Input("rotateWaitSeconds")]
        public Input<int>? RotateWaitSeconds { get; set; }

        /// <summary>
        /// When a monitored file reach it buffer capacity due to a very long line (Buffer_Max_Size), the default behavior is to stop monitoring that file. Skip_Long_Lines alter that behavior and instruct Fluent Bit to skip long lines and continue processing other lines that fits into the buffer size.
        /// </summary>
        [Input("skipLongLines")]
        public Input<bool>? SkipLongLines { get; set; }

        /// <summary>
        /// Set a tag (with regex-extract fields) that will be placed on lines read. E.g. kube.&lt;namespace_name&gt;.&lt;pod_name&gt;.&lt;container_name&gt;
        /// </summary>
        [Input("tag")]
        public Input<string>? Tag { get; set; }

        /// <summary>
        /// Set a regex to exctract fields from the file
        /// </summary>
        [Input("tagRegex")]
        public Input<string>? TagRegex { get; set; }

        public ClusterInputSpecTailArgs()
        {
        }
        public static new ClusterInputSpecTailArgs Empty => new ClusterInputSpecTailArgs();
    }
}
